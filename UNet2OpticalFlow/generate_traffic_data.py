#!/usr/bin/env python

# Copyright (c) 2019 Computer Vision Center (CVC) at the Universitat Autonoma de
# Barcelona (UAB).
#
# This work is licensed under the terms of the MIT license.
# For a copy, see <https://opensource.org/licenses/MIT>.

from multiprocessing.spawn import spawn_main
from queue import Queue
import random
import pdb
import glob
from importlib.resources import path
import os
import time
import queue
import sys
from turtle import distance
import numpy as np
import matplotlib.pyplot as plt
import cv2
import traceback
import argparse

import pandas as pd
print(sys.version_info.major, sys.version_info.minor)
try:
    sys.path.append(glob.glob('PythonAPI/carla/dist/carla-*%d.%d-%s.egg' % (
        sys.version_info.major,
        sys.version_info.minor,
        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])
except IndexError:
    pass
import carla
from carla import VehicleLightState as vls


def visualize_image(image):
    # shape is (image.height * image.width * 4,)
    data = np.array(image.raw_data)
    data_reshaped = np.reshape(data, (image.height, image.width, 4))
    rgb_3channels = data_reshaped[:, :, :3]  # first 3 channels

    cv2.imshow("image", rgb_3channels)
    cv2.waitKey(10)

def draw_waypoints(waypoints, road_id=None, life_time=50.0):
    try:
        for waypoint in waypoints:

            if(waypoint.road_id == road_id):
                carla.DebugHelper.draw_string(waypoint.transform.location, 'O', draw_shadow=False,
                                    color=carla.Color(r=0, g=255, b=0), life_time=life_time,
                                    persistent_lines=True)
    except: 
        print(traceback.format_exc())

# def spawn_actors(case, world):
#     if case == "lateral":
#         spawn = 0
#         transform = world.get_map().get_spawn_points()[spawn]
#         transform.location.y = 310 
#     elif case == "longitudinal":


def main():

    argparser = argparse.ArgumentParser(
        description=__doc__)
    argparser.add_argument(
        '-s', '--scenario',
        metavar="S",
        default='lateral',
        help='either lateral or longitudinal')
    argparser.add_argument(
        '-n', '--number-of-vehicles',
        metavar='N',
        default=150,
        type=int,
        help='number of vehicles (default: 10)')
    argparser.add_argument(
        '-w', '--number-of-walkers',
        metavar='W',
        default=75,
        type=int,
        help='number of walkers (default: 50)')
    argparser.add_argument(
        '--filterv',
        metavar='PATTERN',
        default='vehicle.*',
        help='vehicles filter (default: "vehicle.*")')
    argparser.add_argument(
        '--filterw',
        metavar='PATTERN',
        default='walker.pedestrian.*',
        help='pedestrians filter (default: "walker.pedestrian.*")')
    argparser.add_argument(
        '--car-lights-on',
        action='store_true',
        default=False,
        help='Enanble car lights')
    args = argparser.parse_args()

    ts = str(time.time())
    try:
        path_to_steer = pd.read_csv("_out/path_to_steering.csv", usecols=["path", "steer"])
    except:
        path_to_steer = pd.DataFrame()

    actor_list = []

    # In this tutorial script, we are going to add a vehicle to the simulation
    # and let it drive in autopilot. We will also create a camera attached to
    # that vehicle, and save all the images generated by the camera to disk.

    try:
        # First of all, we need to create the client that will send the requests
        # to the simulator. Here we'll assume the simulator is accepting
        # requests in the localhost at port 2000.
        client = carla.Client('localhost', 4000)
        client.set_timeout(30.0)
        # pdb.set_trace()
        print("Test")
        # Print the possible Towns we have available

        map = "/Game/Carla/Maps/Town01"
        world = client.load_world(map)
        
        settings = world.get_settings()
        settings.synchronous_mode = True
        settings.fixed_delta_seconds = 0.05
        world.apply_settings(settings)
        print("Test")

        tm = client.get_trafficmanager()
        tm.set_synchronous_mode(True)
        # world = client.get_world()
        # world = client.load_world(map)

        # The world contains the list blueprints that we can use for adding new
        # actors into the simulation.
        blueprint_library = world.get_blueprint_library()

        # Now let's filter all the blueprints of type 'vehicle' and choose one
        # at random.
        bp = blueprint_library.find("vehicle.audi.etron")
        # A blueprint contains the list of attributes that define a vehicle's
        # instance, we can read them and modify some of them. For instance,
        # let's randomize its color.
        if bp.has_attribute('color'):
            color = random.choice(bp.get_attribute('color').recommended_values)
            bp.set_attribute('color', color)

        # Now we need to give an initial transform to the vehicle. We choose a
        # random transform from the list of recommended spawn points of the map.
        #transform = random.choice(world.get_map().get_spawn_points())
        # Always fix the starting position


        # 194 longitudinal change
        # 0 for lateral change
        # spawn = random.randrange(len(world.get_map().get_spawn_points()))
        if args.scenario == "lateral":
            # spawn our vehicle 
            spawn = 0
            transform = world.get_map().get_spawn_points()[spawn]
            transform.location.y = 310
       
            vehicle = world.spawn_actor(bp, transform)
            actor_list.append(vehicle)
            print('created %s' % vehicle.type_id)
        
        elif args.scenario == "longitudinal":
            #spawn our vehicle 
            spawn = 30
            transform = world.get_map().get_spawn_points()[spawn]       
            vehicle = world.spawn_actor(bp, transform)
            actor_list.append(vehicle)

        # Lets spawn some traffic 
        spawn_points = world.get_map().get_spawn_points()
        number_of_spawn_points = len(spawn_points)
        blueprints = world.get_blueprint_library().filter(args.filterv)
        blueprintsWalkers = world.get_blueprint_library().filter(args.filterw)

        SpawnActor = carla.command.SpawnActor
        SetAutopilot = carla.command.SetAutopilot
        SetVehicleLightState = carla.command.SetVehicleLightState
        FutureActor = carla.command.FutureActor

        # --------------
        # Spawn vehicles
        # --------------
        actor_list = []
        batch = []
        for n, transform in enumerate(spawn_points):
            if n >= args.number_of_vehicles:
                break
            blueprint = random.choice(blueprints)
            if blueprint.has_attribute('color'):
                color = random.choice(blueprint.get_attribute('color').recommended_values)
                blueprint.set_attribute('color', color)
            if blueprint.has_attribute('driver_id'):
                driver_id = random.choice(blueprint.get_attribute('driver_id').recommended_values)
                blueprint.set_attribute('driver_id', driver_id)
            blueprint.set_attribute('role_name', 'autopilot')

            # prepare the light state of the cars to spawn
            light_state = vls.NONE
            if args.car_lights_on:
                light_state = vls.Position | vls.LowBeam | vls.LowBeam

            # spawn the cars and set their autopilot and light state all together
            batch.append(SpawnActor(blueprint, transform)
                .then(SetAutopilot(FutureActor, True, tm.get_port()))
                .then(SetVehicleLightState(FutureActor, light_state)))

        for response in client.apply_batch_sync(batch, True):
            if response.error:
                print(response.error)
            else:
                actor_list.append(response.actor_id)
        

        # Let's add now a "depth" camera attached to the vehicle. Note that the
        # transform we give here is now relative to the vehicle.
        camera_bp = blueprint_library.find('sensor.camera.depth')
        camera_bp.set_attribute('image_size_x',  str(640))
        camera_bp.set_attribute('image_size_y',  str(320))
        camera_transform = carla.Transform(carla.Location(x=1.5, z=2.4))
        camera = world.spawn_actor(
            camera_bp, camera_transform, attach_to=vehicle)
        actor_list.append(camera)
        print('created %s' % camera.type_id)

        frame = 0

        # check if dir is already there
        if not os.path.isdir("_out/%s-%s/%s" % (map.split('/')[-1], spawn, ts)):
            os.makedirs("_out/%s-%s/%s" % (map.split('/')[-1], spawn, ts))


        # Now we register the function that will be called each time the sensor
        # receives an image. In this example we are saving the image to disk
        # converting the pixels to gray-scale.
        depth_image_queue = queue.Queue()
        cc = carla.ColorConverter.LogarithmicDepth
        # camera.listen(lambda image: image.save_to_disk('_out/%s-%s/depth-%d.png' % (map.split('/')[-1], spawn, frame), cc) if frame>10 else None)
        camera.listen(depth_image_queue.put)

        # also get and save rgb values
        camera_bp_rgb_car = blueprint_library.find('sensor.camera.rgb')
        camera_bp_rgb_car.set_attribute('image_size_x',  str(640))
        camera_bp_rgb_car.set_attribute('image_size_y',  str(320))
        camera_bp_rgb_car.set_attribute('fov',  str(100))
        camera_transform_rgb_car = carla.Transform(
            carla.Location(x=1.5, z=2.4))
        camera_rgb_car = world.spawn_actor(
            camera_bp_rgb_car, camera_transform_rgb_car, attach_to=vehicle)
        actor_list.append(camera_rgb_car)
        print('created %s' % camera_rgb_car.type_id)
        rgb_image_queue = queue.Queue()
        # camera_rgb_car.listen(lambda image: image.save_to_disk('_out/%s-%s/rgb-%d.png' % (map.split('/')[-1], spawn, frame)) if frame > 10 else None)
        camera_rgb_car.listen(rgb_image_queue.put)

        rgb_list = list()

        # Let's add now an "RGB" camera attached to the vehicle.
        camera_bp_rgb = blueprint_library.find('sensor.camera.rgb')
        camera_bp_rgb.set_attribute('image_size_x',  str(640))
        camera_bp_rgb.set_attribute('image_size_y',  str(320))
        camera_bp_rgb.set_attribute('fov',  str(100))
        camera_transform_rgb = carla.Transform(carla.Location(x=-7.0, z=2.4))
        camera_rgb = world.spawn_actor(
            camera_bp_rgb, camera_transform_rgb, attach_to=vehicle)
        actor_list.append(camera_rgb)
        print('created %s' % camera_rgb.type_id)
        camera_rgb.listen(lambda image: rgb_list.append(
            image) if frame > 10 else None)

  

        # # But the city now is probably quite empty, let's add a few more
        # # vehicles.
        # transform.location += carla.Location(x=40, y=-3.2)
        # transform.rotation.yaw = -180.0
        # for _ in range(0, 10):
        #     transform.location.x += 8.0
        #
        #     bp = random.choice(blueprint_library.filter('vehicle'))
        #
        #     # This time we are using try_spawn_actor. If the spot is already
        #     # occupied by another object, the function will return None.
        #     npc = world.try_spawn_actor(bp, transform)
        #     if npc is not None:
        #         actor_list.append(npc)
        #         npc.set_autopilot()
        #         print('created %s' % npc.type_id)

        # init random frames 


        for frame in range(500):
            # Do tick
            world.tick()
            
            if frame > 100: 
                # Get synced images
                rgb_image = rgb_image_queue.get()
                depth_image = depth_image_queue.get()
                if frame % 10 == 0:
                    rgb_image.save_to_disk(
                        '_out/%s-%s/%s/CameraRGB/rgb-%d.png' % (map.split('/')[-1], spawn, ts, frame))
                    depth_image.save_to_disk(
                        '_out/%s-%s/%s/CameraDepth/depth-%d.png' % (map.split('/')[-1], spawn, ts, frame))

            
                # visualize_image(rgb_list[-1])
                # For applying manual control. Make sure that the vehicle.set_autopilot(True) is commented out above
                # vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=0.0))
                # Always have the traffic light on green
                if vehicle.is_at_traffic_light():
                    traffic_light = vehicle.get_traffic_light()
                    if traffic_light.get_state() == carla.TrafficLightState.Red:
                        traffic_light.set_state(carla.TrafficLightState.Green)

                print('frame %s' % frame)
                print("Throttle: {}, Steering: {}".format(
                    vehicle.get_control().throttle, vehicle.get_control().steer))
                print("Vehicle location: (x,y,z): ({},{},{})".format(
                    vehicle.get_location().x, vehicle.get_location().y, vehicle.get_location().z))
                print("Vehicle transform: ", vehicle.get_transform())

                if frame % 10 == 0:
                    path = '_out/%s-%s/%s/%d.png' % (map.split('/')
                                                    [-1], spawn, ts, frame)
                    new_row = pd.DataFrame(
                        [[path, vehicle.get_control().steer]], columns=["path", "steer"])
                    path_to_steer = path_to_steer.append(
                        new_row, ignore_index=True)
                # pdb.set_trace()

        # time.sleep(5)

        path_to_steer.to_csv('_out/path_to_steering.csv')
    except Exception as e:
        exc_type, exc_obj, exc_tb = sys.exc_info()
        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
        print(exc_type, fname, exc_tb.tb_lineno)
        print(traceback.format_exc())


    finally:
        try:
            print('destroying actors')
            camera.destroy()
            camera_rgb.destroy()
            camera_rgb_car.destroy()
            client.apply_batch([carla.command.DestroyActor(x) for x in actor_list])
            print('done.')
        except: 
            pass


if __name__ == '__main__':
    for i in range(1):
        try:
            print("Iteration: ", i)
            main()
        except Exception as e:
            print(e)
            pass
