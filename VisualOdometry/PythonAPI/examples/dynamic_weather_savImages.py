#!/usr/bin/env python

# Copyright (c) 2019 Computer Vision Center (CVC) at the Universitat Autonoma de
# Barcelona (UAB).
#
# This work is licensed under the terms of the MIT license.
# For a copy, see <https://opensource.org/licenses/MIT>.

import glob
import os
import sys
import numpy as np
import matplotlib.pyplot as plt
import cv2

try:
    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (
        sys.version_info.major,
        sys.version_info.minor,
        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])
except IndexError:
    pass

import carla
import pdb

import random
import time
import pdb


def visualize_image(image):
    data = np.array(image.raw_data)  # shape is (image.height * image.width * 4,)
    data_reshaped = np.reshape(data, (image.height, image.width, 4))
    rgb_3channels = data_reshaped[:, :, :3]  # first 3 channels

    cv2.imshow("image", rgb_3channels)
    cv2.waitKey(10)


def main():
    actor_list = []

    # In this tutorial script, we are going to add a vehicle to the simulation
    # and let it drive in autopilot. We will also create a camera attached to
    # that vehicle, and save all the images generated by the camera to disk.

    try:
        # First of all, we need to create the client that will send the requests
        # to the simulator. Here we'll assume the simulator is accepting
        # requests in the localhost at port 2000.
        client = carla.Client('localhost', 2000)
        client.set_timeout(20.0)
        # pdb.set_trace()

        # Print the possible Towns we have available
        print(client.get_available_maps())
        # Once we have a client we can retrieve the world that is currently
        # running.
        # world = client.get_world()
        world = client.load_world("/Game/Carla/Maps/Town05")



        # The world contains the list blueprints that we can use for adding new
        # actors into the simulation.
        blueprint_library = world.get_blueprint_library()

        # Now let's filter all the blueprints of type 'vehicle' and choose one
        # at random.
        bp = random.choice(blueprint_library.filter('vehicle'))

        # A blueprint contains the list of attributes that define a vehicle's
        # instance, we can read them and modify some of them. For instance,
        # let's randomize its color.
        if bp.has_attribute('color'):
            color = random.choice(bp.get_attribute('color').recommended_values)
            bp.set_attribute('color', color)

        # Now we need to give an initial transform to the vehicle. We choose a
        # random transform from the list of recommended spawn points of the map.
        transform = random.choice(world.get_map().get_spawn_points())
        # Always fix the starting position
        # transform = world.get_map().get_spawn_points()[0]
        # pdb.set_trace()

        # So let's tell the world to spawn the vehicle.
        vehicle = world.spawn_actor(bp, transform)

        # It is important to note that the actors we create won't be destroyed
        # unless we call their "destroy" function. If we fail to call "destroy"
        # they will stay in the simulation even after we quit the Python script.
        # For that reason, we are storing all the actors we create so we can
        # destroy them afterwards.
        actor_list.append(vehicle)
        print('created %s' % vehicle.type_id)

        # Let's put the vehicle to drive around.
        vehicle.set_autopilot(False)

        # Let's add now a "depth" camera attached to the vehicle. Note that the
        # transform we give here is now relative to the vehicle.
        # camera_bp = blueprint_library.find('sensor.camera.depth')
        # camera_transform = carla.Transform(carla.Location(x=1.5, z=2.4))
        # camera = world.spawn_actor(camera_bp, camera_transform, attach_to=vehicle)
        # actor_list.append(camera)
        # print('created %s' % camera.type_id)

        frame = 0

        # Now we register the function that will be called each time the sensor
        # receives an image. In this example we are saving the image to disk
        # converting the pixels to gray-scale.
        # cc = carla.ColorConverter.LogarithmicDepth
        # camera.listen(lambda image: image.save_to_disk('_out/%06d.png' % frame, cc) if frame > 10 else None)

        rgb_list = list()

        # Let's add now an "RGB" camera attached to the vehicle.
        camera_bp_rgb = blueprint_library.find('sensor.camera.rgb')
        camera_bp_rgb.set_attribute('image_size_x', str(640))
        camera_bp_rgb.set_attribute('image_size_y', str(320))
        camera_bp_rgb.set_attribute('fov', str(90))
        camera_transform_rgb = carla.Transform(carla.Location(x=-2.0, z=2.4))
        camera_rgb = world.spawn_actor(camera_bp_rgb, camera_transform_rgb, attach_to=vehicle)
        actor_list.append(camera_rgb)
        print('created %s' % camera_rgb.type_id)
        camera_rgb.listen(lambda image: rgb_list.append(image) if frame > 10 else None)

        # Oh wait, I don't like the location we gave to the vehicle, I'm going
        # to move it a bit forward.
        location = vehicle.get_location()
        location.x += 1
        vehicle.set_location(location)
        print('moved vehicle to %s' % location)

        # # But the city now is probably quite empty, let's add a few more
        # # vehicles.
        # transform.location += carla.Location(x=40, y=-3.2)
        # transform.rotation.yaw = -180.0
        # for _ in range(0, 10):
        #     transform.location.x += 8.0
        #
        #     bp = random.choice(blueprint_library.filter('vehicle'))
        #
        #     # This time we are using try_spawn_actor. If the spot is already
        #     # occupied by another object, the function will return None.
        #     npc = world.try_spawn_actor(bp, transform)
        #     if npc is not None:
        #         actor_list.append(npc)
        #         npc.set_autopilot()
        #         print('created %s' % npc.type_id)


        weather = carla.WeatherParameters(
            cloudiness=80.0,
            precipitation_deposits=0.0,
            sun_altitude_angle=30.0)

        world.set_weather(weather)

        print(world.get_weather())

        for frame in range(100):
            # Do tick
            world.tick()
            if frame > 10:
                visualize_image(rgb_list[-1])
                # pdb.set_trace()
                camera_rgb.destroy()

                client.apply_batch([carla.command.DestroyActor(x) for x in [actor_list[-1]]])
                actor_list = actor_list[:-1]
                camera_bp_rgb = blueprint_library.find('sensor.camera.rgb')
                camera_bp_rgb.set_attribute('image_size_x', str(640))
                camera_bp_rgb.set_attribute('image_size_y', str(320))
                camera_bp_rgb.set_attribute('fov', str(90))
                y = -5.0 + (frame-10) * 0.1
                print(y)
                camera_transform_rgb = carla.Transform(carla.Location(x = 1.0,y=y, z=2.4), carla.Rotation(pitch = -20))
                camera_rgb = world.spawn_actor(camera_bp_rgb, camera_transform_rgb, attach_to=vehicle)
                actor_list.append(camera_rgb)
                print('created %s' % camera_rgb.type_id)
                camera_rgb.listen(lambda image: image.save_to_disk('_out3/%06d.png' % (frame - 10)) if frame > 10 else None)
                # camera_rgb.listen(lambda image: rgb_list.append(image) if frame > 10 else None)



            # For applying manual control. Make sure that the vehicle.set_autopilot(True) is commented out above
            # vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=0.0))
            # Always have the traffic light on green
            if vehicle.is_at_traffic_light():
                traffic_light = vehicle.get_traffic_light()
                if traffic_light.get_state() == carla.TrafficLightState.Red:
                    traffic_light.set_state(carla.TrafficLightState.Green)

            print('frame %s' % frame)
            print("Throttle: {}, Steering: {}".format(vehicle.get_control().throttle, vehicle.get_control().steer))
            print("Vehicle location: (x,y,z): ({},{},{})".format(vehicle.get_location().x, vehicle.get_location().y,
                                                                 vehicle.get_location().z))

            # pdb.set_trace()

        # time.sleep(5)

    finally:

        print('destroying actors')
        # camera.destroy()
        camera_rgb.destroy()
        client.apply_batch([carla.command.DestroyActor(x) for x in actor_list])
        print('done.')


if __name__ == '__main__':
    main()
